{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp diff_analysis_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ConfigOfRunPipeline:\n",
    "    \"\"\"Stores all the parameters given to the \"run_pipeline\" function\"\"\"\n",
    "    def __init__(self, locals):\n",
    "        for k, v in locals.items():\n",
    "            setattr(self, k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import statsmodels.stats.multitest as mt\n",
    "from time import time\n",
    "import directlfq.diffquant_utils as aqutils\n",
    "import directlfq.visualizations as aqviz\n",
    "\n",
    "import directlfq.ptmsite_mapping as aqptm\n",
    "import multiprocess\n",
    "\n",
    "\n",
    "def run_pipeline(*,input_file = None, samplemap_file=None, samplemap_df = None, ml_input_file = None,modification_type = None, input_type_to_use = None,results_dir = \"./results\", condpair_combinations = None, minrep = 2, \n",
    "min_num_ions = 1, minpep = 1, cluster_threshold_pval = 0.05, cluster_threshold_fcfc = 0, use_ml = True, take_median_ion = True,outlier_correction = True, normalize = True,\n",
    "use_iontree_if_possible = None, write_out_results_tree = True, get_ion2clust = False, median_offset = False, pre_normed_intensity_file = None, dia_fragment_selection = False, use_multiprocessing = False,runtime_plots = False, volcano_fdr =0.05, volcano_fcthresh = 0.5, \n",
    "annotation_file = None, protein_subset_for_normalization_file = None):\n",
    "\n",
    "    \"\"\"Run the differential analyses.\n",
    "    \"\"\"\n",
    "    \n",
    "    check_input_consistency(input_file, samplemap_file, samplemap_df)\n",
    "\n",
    "\n",
    "\n",
    "    if samplemap_df is None:\n",
    "        samplemap_df = aqutils.load_samplemap(samplemap_file)\n",
    "    \n",
    "    if modification_type is not None:\n",
    "        \n",
    "        input_file = write_ptm_mapped_input(input_file=input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type)\n",
    "\n",
    "    if \"aq_reformat.tsv\" not in input_file:\n",
    "        input_file = aqutils.reformat_and_save_input_file(input_file, input_type_to_use = input_type_to_use)\n",
    "    \n",
    "    \n",
    "    #use runconfig object to store the parameters\n",
    "    runconfig = ConfigOfRunPipeline(locals()) #all the parameters given into the function are transfered to the runconfig object!\n",
    "    runconfig.use_iontree_if_possible = determine_if_ion_tree_is_used(runconfig)\n",
    "\n",
    "    #store method parameters for reproducibility\n",
    "    aqutils.remove_old_method_parameters_file_if_exists(results_dir)\n",
    "    aqutils.store_method_parameters(locals(), results_dir)\n",
    "    \n",
    "    if runconfig.use_iontree_if_possible and use_ml and not ml_input_file:\n",
    "        reformat_and_save_ml_dataframe(results_dir, samplemap_df)\n",
    "\n",
    "    if condpair_combinations == None:\n",
    "        conds = samplemap_df[\"condition\"].unique()\n",
    "        condpair_combinations = combinations(conds, 2)\n",
    "    \n",
    "    num_cores = get_num_cores_to_use(use_multiprocessing)\n",
    "\n",
    "    if num_cores == 1:\n",
    "        run_analysis_singleprocess(condpair_combinations=condpair_combinations, runconfig=runconfig)\n",
    "\n",
    "    else:\n",
    "        run_analysis_multiprocess(condpair_combinations=condpair_combinations, runconfig=runconfig, num_cores=num_cores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reformat_and_save_ml_dataframe(results_dir, samplemap_df):\n",
    "    all_samples = aqutils.get_all_samples_from_samplemap_df(samplemap_df)\n",
    "    dfhandler = aqutils.AcquisitionTableHandler(results_dir=results_dir,samples=all_samples)\n",
    "    dfhandler.save_dataframe_as_new_acquisition_dataframe()\n",
    "    dfhandler.update_ml_file_location_in_method_parameters_yaml()\n",
    "\n",
    "def get_num_cores_to_use(use_multiprocessing):\n",
    "    num_cores = multiprocess.cpu_count() if use_multiprocessing else 1\n",
    "    return min(num_cores, 10)\n",
    "\n",
    "def run_analysis_singleprocess(condpair_combinations, runconfig):\n",
    "\n",
    "    for condpair in condpair_combinations:\n",
    "        analyze_condpair(runconfig=runconfig, condpair=condpair)\n",
    "\n",
    "def run_analysis_multiprocess(condpair_combinations, runconfig, num_cores):\n",
    "\n",
    "    with multiprocess.Pool(num_cores) as pool:\n",
    "        \n",
    "        pool.map(lambda condpair : \n",
    "\n",
    "        analyze_condpair(runconfig= runconfig, condpair = condpair)\n",
    "        \n",
    "        ,condpair_combinations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import directlfq.ptmsite_mapping as aqptm\n",
    "\n",
    "def write_ptm_mapped_input(input_file, results_dir, samplemap_df, modification_type):\n",
    "    try:\n",
    "        aqptm.assign_dataset_inmemory(input_file = input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type)\n",
    "    except:\n",
    "        aqptm.assign_dataset_chunkwise(input_file = input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type)\n",
    "    mapped_df = pd.read_csv(f\"{results_dir}/ptm_ids.tsv\", sep = \"\\t\")\n",
    "    ptm_mapped_file = aqptm.merge_ptmsite_mappings_write_table(input_file, mapped_df, modification_type)\n",
    "    return ptm_mapped_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def check_input_consistency(input_file, samplemap_file, samplemap_df):\n",
    "    if input_file is None:\n",
    "        raise Exception(\"no input file!\")\n",
    "    if samplemap_file is None and samplemap_df is None:\n",
    "        raise Exception(\"inputs inconsistent! Either file or dataframe needs to be specified!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import directlfq.diffquant_utils as aqutils\n",
    "def get_unnormed_df_condpair(input_file:str, samplemap_df:pd.DataFrame, condpair:str) -> pd.DataFrame:\n",
    "\n",
    "\n",
    "    samples_c1, samples_c2 = aqutils.get_samples_used_from_samplemap_df(samplemap_df=samplemap_df, cond1 = condpair[0], cond2 = condpair[1])\n",
    "    used_samples = samples_c1+samples_c2\n",
    "    unnormed_df = aqutils.import_data(input_file,samples_subset=used_samples)\n",
    "    unnormed_df, _ = aqutils.prepare_loaded_tables(unnormed_df, samplemap_df)\n",
    "    return unnormed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_per_condition_dataframes(samples_c1, samples_c2, unnormed_df, minrep):\n",
    "\n",
    "    min_samples = min(len(samples_c1), len(samples_c2))\n",
    "\n",
    "    if min_samples<2:\n",
    "        raise Exception(f\"condpair has not enough samples: c1:{len(samples_c1)} c2: {len(samples_c2)}, skipping\")\n",
    "\n",
    "    minrep_c1 = get_minrep_for_cond(samples_c1, minrep)\n",
    "    minrep_c2 = get_minrep_for_cond(samples_c2, minrep)\n",
    "    df_c1 = unnormed_df.loc[:, samples_c1].dropna(thresh=minrep_c1, axis=0)\n",
    "    df_c2 = unnormed_df.loc[:, samples_c2].dropna(thresh=minrep_c2, axis=0)\n",
    "    if (len(df_c1.index)<5) | (len(df_c2.index)<5):\n",
    "        raise Exception(f\"condpair has not enough data for processing c1: {len(df_c1.index)} c2: {len(df_c2.index)}, skipping\")\n",
    "        \n",
    "    return df_c1, df_c2\n",
    "\n",
    "def get_minrep_for_cond(c_samples, minrep):\n",
    "    if minrep is None: #in the case of None, no nans will be allowed\n",
    "        return None\n",
    "    num_samples = len(c_samples)\n",
    "    if num_samples<minrep:\n",
    "        return num_samples\n",
    "    else:\n",
    "        return minrep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import directlfq.diffquant_utils as aqutils\n",
    "def determine_if_ion_tree_is_used(runconfig):\n",
    "    if runconfig.use_iontree_if_possible is not None:\n",
    "        return runconfig.use_iontree_if_possible\n",
    "    _, config_dict, _ =  aqutils.get_input_type_and_config_dict(runconfig.input_file)\n",
    "    return config_dict.get(\"use_iontree\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import directlfq.background_distributions as aqbg\n",
    "import directlfq.diff_analysis as aqdiff\n",
    "import directlfq.normalization as aqnorm\n",
    "import directlfq.visualizations as aqviz\n",
    "import directlfq.diffquant_utils as aqutils\n",
    "import directlfq.cluster_ions as aqclust\n",
    "import directlfq.classify_ions as aqclass\n",
    "import anytree\n",
    "\n",
    "def analyze_condpair(*,runconfig, condpair):\n",
    "    t_zero = time()\n",
    "    print(f\"start processeing condpair {condpair}\")\n",
    "    prot2diffions = {}\n",
    "    p2z = {}\n",
    "    ion2clust = {}\n",
    "    protnodes = []\n",
    "    quantified_peptides = []\n",
    "    quantified_proteins = []\n",
    "    \n",
    "    \n",
    "    input_df_local = get_unnormed_df_condpair(input_file=runconfig.input_file, samplemap_df=runconfig.samplemap_df, condpair=condpair)\n",
    "    pep2prot = dict(zip(input_df_local.index, input_df_local['protein']))\n",
    "    c1_samples, c2_samples = aqutils.get_samples_used_from_samplemap_df(runconfig.samplemap_df, condpair[0], condpair[1])\n",
    "\n",
    "    try:\n",
    "        df_c1, df_c2 = get_per_condition_dataframes(c1_samples, c2_samples, input_df_local, runconfig.minrep)\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    df_c1_normed, df_c2_normed = aqnorm.normalize_if_specified(df_c1 = df_c1, df_c2 = df_c2, c1_samples = c1_samples, c2_samples = c2_samples, minrep = runconfig.minrep, normalize_within_conds = runconfig.normalize, normalize_between_conds = runconfig.normalize, \n",
    "    runtime_plots = runconfig.runtime_plots, protein_subset_for_normalization_file=runconfig.protein_subset_for_normalization_file, pep2prot = pep2prot,prenormed_file = runconfig.pre_normed_intensity_file)#, \"./test_data/normed_intensities.tsv\")\n",
    "    \n",
    "    if runconfig.results_dir != None:\n",
    "        write_out_normed_df(df_c1_normed,df_c2_normed, pep2prot, runconfig.results_dir, condpair)\n",
    "    t_normalized = time()\n",
    "    normed_c1 = aqbg.ConditionBackgrounds(df_c1_normed, p2z)\n",
    "    normed_c2 = aqbg.ConditionBackgrounds(df_c2_normed, p2z)\n",
    "\n",
    "    t_bgdist_fin = time()\n",
    "    ions_to_check = normed_c1.ion2nonNanvals.keys() & normed_c2.ion2nonNanvals.keys()\n",
    "    use_ion_tree = runconfig.use_iontree_if_possible\n",
    "    bgpair2diffDist = {}\n",
    "    deedpair2doublediffdist = {}\n",
    "    count_ions=0\n",
    "    for ion in ions_to_check:\n",
    "        t_ion = time()\n",
    "        vals1 = normed_c1.ion2nonNanvals.get(ion)\n",
    "        vals2 = normed_c2.ion2nonNanvals.get(ion)\n",
    "        bg1 = normed_c1.ion2background.get(ion)\n",
    "        bg2 = normed_c2.ion2background.get(ion)\n",
    "        diffDist = aqbg.get_subtracted_bg(bgpair2diffDist, bg1, bg2, p2z)\n",
    "        t_subtract_end = time()\n",
    "        diffIon = aqdiff.DifferentialIon(vals1, vals2, diffDist, ion, runconfig.outlier_correction)\n",
    "        t_diffion = time()\n",
    "        protein = pep2prot.get(ion)\n",
    "        prot_ions = prot2diffions.get(protein, list())\n",
    "        prot_ions.append(diffIon)\n",
    "        prot2diffions[protein] = prot_ions\n",
    "        quantified_peptide = QuantifiedResult(kwargs = {'ion' : ion, 'pval' : diffIon.p_val, 'log2fc' : diffIon.fc, 'protein' : protein, 'condpair' : aqutils.get_condpairname(condpair)})\n",
    "        quantified_peptides.append(quantified_peptide)\n",
    "\n",
    "\n",
    "        if count_ions%2000==0:\n",
    "            print(f\"checked {count_ions} of {len(ions_to_check)} ions\")\n",
    "\n",
    "        count_ions+=1\n",
    "\n",
    "        t_iterfin = time()\n",
    "        #print(f\"t_init {t_subtract_start-t_ion} t_diffdist {t_subtract_end -t_subtract_start} t_diffion {t_iterfin - t_ion}\")\n",
    "    count_prots = 0\n",
    "    for prot in prot2diffions.keys():\n",
    "        ions = prot2diffions.get(prot)\n",
    "        if len(ions)<runconfig.min_num_ions:\n",
    "            continue\n",
    "        diffprot = aqdiff.DifferentialProtein(prot, ions, runconfig.median_offset, runconfig.dia_fragment_selection)\n",
    "        if use_ion_tree:\n",
    "            clustered_root_node = aqclust.get_scored_clusterselected_ions(prot, ions, normed_c1, normed_c2, bgpair2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis = runconfig.cluster_threshold_pval, fcfc_threshold = runconfig.cluster_threshold_fcfc, take_median_ion=runconfig.take_median_ion)\n",
    "            #print(anytree.RenderTree(clustered_root_node))\n",
    "            #if not clustered_root_node.is_included:\n",
    "             #   continue\n",
    "            protnodes.append(clustered_root_node)\n",
    "            pval, fc, consistency_score, ions_included = aqclust.get_diffresults_from_clust_root_node(clustered_root_node)\n",
    "            num_peptides = len(anytree.findall(clustered_root_node, filter_ = lambda x : x.type == 'seq'))\n",
    "            if num_peptides < runconfig.minpep:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            pval, fc, consistency_score, ions_included = diffprot.pval, diffprot.fc, np.nan,diffprot.ions\n",
    "\n",
    "        if runconfig.get_ion2clust:\n",
    "            ionclust_protein = aqclust.find_fold_change_clusters_base_ions([[x] for x in ions],normed_c1,normed_c2, bgpair2diffDist,p2z, deedpair2doublediffdist, fc_threshold=runconfig.cluster_threshold_fcfc, pval_threshold_basis=runconfig.cluster_threshold_pval)\n",
    "            ion2clust.update({x.name:y for x,y in ionclust_protein.items()})\n",
    "        \n",
    "        if count_prots%100==0:\n",
    "            print(f\"checked {count_prots} of {len(prot2diffions.keys())} prots\")\n",
    "        count_prots+=1\n",
    "\n",
    "        pseudoint1_cond, pseudoint2_cond = aqdiff.calc_pseudo_intensities(ions, normed_c2, diffprot.fc)\n",
    "        quantified_protein = QuantifiedResult(kwargs={'condpair': aqutils.get_condpairname(condpair), 'protein' : prot, 'fdr' : 1.0, 'pval':pval,'log2fc': fc, 'consistency_score' : consistency_score, 'num_ions' : len(ions_included), 'pseudoint1' : pseudoint1_cond, 'pseudoint2' : pseudoint2_cond})\n",
    "        quantified_proteins.append(quantified_protein)\n",
    "    \n",
    "    if use_ion_tree:\n",
    "        if runconfig.use_ml:\n",
    "            ml_performance_dict = {}\n",
    "            ml_successfull = True\n",
    "            aqclass.assign_predictability_scores(protnodes, runconfig.results_dir, name = aqutils.get_condpairname(condpair), samples_used = c1_samples+ c2_samples,precursor_cutoff=3, \n",
    "            fc_cutoff=0.5, number_splits=5, plot_predictor_performance=runconfig.runtime_plots, replace_nans=True, performance_metrics=ml_performance_dict)\n",
    "\n",
    "            \n",
    "            if (ml_performance_dict[\"r2_score\"] >0.05) and ml_successfull: #only use the ml score if it is meaningful\n",
    "                aqclust.update_nodes_w_ml_score(protnodes)\n",
    "                update_quantified_proteins_w_tree_results(quantified_proteins, protnodes)\n",
    "\n",
    "    \n",
    "    add_fdr(quantified_proteins)\n",
    "    add_fdr(quantified_peptides)\n",
    "    \n",
    "    res_df = get_results_df(quantified_proteins)\n",
    "    pep_df = get_results_df(quantified_peptides)\n",
    "\n",
    "    if runconfig.runtime_plots:\n",
    "        aqviz.volcano_plot(res_df, significance_cutoff = runconfig.volcano_fdr, log2fc_cutoff = runconfig.volcano_fcthresh)\n",
    "        aqviz.volcano_plot(pep_df,significance_cutoff = runconfig.volcano_fdr, log2fc_cutoff = runconfig.volcano_fcthresh)\n",
    "\n",
    "    if runconfig.results_dir!=None:\n",
    "\n",
    "        if runconfig.write_out_results_tree:\n",
    "            aqclust.export_roots_to_json(protnodes,condpair,runconfig.results_dir)\n",
    "        if runconfig.annotation_file != None: #additional annotations can be added before saving\n",
    "            annot_df = pd.read_csv(runconfig.annotation_file, sep = \"\\t\")\n",
    "            intersect_columns = annot_df.columns.intersection(pep_df.columns)\n",
    "            if(len(intersect_columns)>0):\n",
    "                print(list(intersect_columns))\n",
    "                res_df = res_df.merge(annot_df, on=list(intersect_columns), how= 'left')\n",
    "                pep_df = pep_df.merge(annot_df, on= list(intersect_columns), how = 'left')\n",
    "\n",
    "\n",
    "        \n",
    "        if runconfig.get_ion2clust:\n",
    "            ion2clust_df = pd.DataFrame(ion2clust.items(), columns=['ion', 'cluster'])\n",
    "            ion2clust_df.to_csv(f\"{runconfig.results_dir}/{aqutils.get_condpairname(condpair)}.ion2clust.tsv\", sep = \"\\t\", index=None)\n",
    "\n",
    "        res_df.to_csv(f\"{runconfig.results_dir}/{aqutils.get_condpairname(condpair)}.results.tsv\", sep = \"\\t\", index=None)\n",
    "        pep_df.to_csv(f\"{runconfig.results_dir}/{aqutils.get_condpairname(condpair)}.results.ions.tsv\", sep = \"\\t\", index=None)\n",
    "    \n",
    "    print(f\"\\ncondition pair {condpair} finished!\\n\")\n",
    "\n",
    "\n",
    "    return res_df, pep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ion': 'ion', 'pval': 23, 'log2fc': 123.2, 'protein': 'protein', 'condpair': 'aqutils.get_condpairname(condpair)'}\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "#helper class to store diffresults\n",
    "class QuantifiedResult:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.propdict = None\n",
    "        if kwargs:\n",
    "            self.propdict = kwargs['kwargs']\n",
    "    def add_property(self, key, value):\n",
    "        self.propdict[key]  = value\n",
    "    def add_properties(self, dict):\n",
    "        self.propdict.update(dict)\n",
    "\n",
    "\n",
    "def update_quantified_proteins_w_tree_results(quantified_proteins, protnodes):\n",
    "    prot2fc = {x.name : x.fc for x in protnodes}\n",
    "    prot2pval = {x.name : x.p_val  for x in protnodes}\n",
    "    prot2predscore = {x.name : x.predscore for x in protnodes}\n",
    "    for quantified_protein in quantified_proteins:\n",
    "        protname = quantified_protein.propdict['protein']\n",
    "        quantified_protein.propdict['log2fc'] = prot2fc.get(protname)\n",
    "        quantified_protein.propdict['pval'] = prot2pval.get(protname)\n",
    "        quantified_protein.propdict['predscore'] = prot2predscore.get(protname)\n",
    "\n",
    "\n",
    "def add_fdr(quantified_results):\n",
    "    pvals = [x.propdict[\"pval\"] for x in quantified_results]\n",
    "    fdrs = mt.multipletests(pvals, method='fdr_bh', is_sorted=False, returnsorted=False)[1]\n",
    "    for idx in range(len(quantified_results)):\n",
    "        quantified_results[idx].propdict['fdr'] = fdrs[idx]\n",
    "\n",
    "def get_results_df(quantfied_results):\n",
    "    quantified_results_dicts = [x.propdict for x in quantfied_results]\n",
    "    res_df = pd.DataFrame(quantified_results_dicts)\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import os\n",
    "def write_out_normed_df(normed_df_1, normed_df_2, pep2prot, results_dir, condpair):\n",
    "    merged_df = normed_df_1.merge(normed_df_2, left_index = True, right_index = True)\n",
    "    merged_df = 2**merged_df\n",
    "    merged_df = merged_df.replace(np.nan, 0)\n",
    "    merged_df[\"protein\"] = list(map(lambda x : pep2prot.get(x),merged_df.index))\n",
    "    if not os.path.exists(f\"{results_dir}/\"):\n",
    "        os.makedirs(f\"{results_dir}/\")\n",
    "    merged_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.normed.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_normed_dfs(normed_df_1, normed_df_2, condpair):\n",
    "    merged_df = normed_df_1.merge(normed_df_2, left_index = True, right_index = True)\n",
    "    merged_df = 2**merged_df\n",
    "    merged_df = merged_df.replace(np.nan, 0)\n",
    "    merged_df[\"condpair\"] = condpair\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read in proteomics datafiles, log the intensities\n",
    "def read_tables(peptides_tsv, samplemap_tsv, pepheader = None, protheader = None):\n",
    "    samplemap = pd.read_csv(samplemap_tsv, sep=\"\\t\")\n",
    "    peps = pd.read_csv(peptides_tsv,sep=\"\\t\")\n",
    "\n",
    "    if pepheader != None:\n",
    "        peps = peps.rename(columns = {pepheader : \"ion\"})\n",
    "    if protheader != None:\n",
    "        peps = peps.rename(columns = {protheader: \"protein\"})\n",
    "    peps = peps.set_index(\"ion\")\n",
    "    headers = ['protein'] + samplemap[\"sample\"].to_list()\n",
    "\n",
    "    for sample in samplemap[\"sample\"]:\n",
    "        peps[sample] = np.log2(peps[sample].replace(0, np.nan))\n",
    "    return peps[headers], samplemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "\n",
    "def write_out_ion2nonan_ion2idx(cb, outfolder, condname):\n",
    "    \n",
    "    ion2nan_conv = [[a, x.tolist()] for a, x in cb.ion2nonNanvals.items()]\n",
    "    \n",
    "    ion2nan_df = pd.DataFrame(ion2nan_conv)\n",
    "    display(ion2nan_df)\n",
    "    print(ion2nan_df.iloc[41775, 1])\n",
    "    idx2ion_df = pd.DataFrame(list(cb.idx2ion.items()))\n",
    "\n",
    "    ion2nan_df.to_csv(f\"{outfolder}/ion2nonans_{condname}.tsv\", sep = \"\\t\", index = False)\n",
    "    idx2ion_df.to_csv(f\"{outfolder}/idx2ion_{condname}.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def compare_context_boundaries_against_ref(ref_file, cond_bg):\n",
    "    ref_bounds = pd.read_csv(ref_file, sep = \"\\t\", names = [\"l_ref\", \"u_ref\"])\n",
    "    ref_bounds[\"l\"] = pd.Series(np.array(cond_bg.context_ranges).T[0])\n",
    "    ref_bounds[\"u\"] = pd.Series(np.array(cond_bg.context_ranges).T[1])\n",
    "    ref_bounds[\"l-ref\"] = (ref_bounds[\"l_ref\"] / ref_bounds[\"l\"]).abs()\n",
    "    ref_bounds[\"u-ref\"] = (ref_bounds[\"u_ref\"] / ref_bounds[\"u\"]).abs()\n",
    "    display(ref_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "#protein_df, peptide_df = benchmark_proteomics(\"./test_data/peptides.txt\", \"./test_data/samples.map\", \"./test_data/prot2organism.tsv\")\n",
    "#protein_df.to_csv(\"./test_data/AP_protein_out.tsv\", sep = \"\\t\", index= False)\n",
    "#peptide_df.to_csv(\"./test_data/AP_peptide_out.tsv\", sep = \"\\t\", index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/Users/constantin/workspace/EmpiRe/nbdev/MS-EmpiRe_Python')\n",
    "# from directlfq.background_distributions import *\n",
    "# from directlfq.normalization import *\n",
    "# from directlfq.diff_analysis import *\n",
    "# from directlfq.visualizations import *\n",
    "# from directlfq.benchmarking import *\n",
    "# from directlfq.diffquant_utils import *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
